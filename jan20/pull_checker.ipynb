{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting credentials from json...\n",
      "\n",
      "Opening spreadsheet...\n"
     ]
    }
   ],
   "source": [
    "# Import libraries:\n",
    "import csv\n",
    "import os\n",
    "import urllib.request, json \n",
    "from urllib.request import urlopen, Request\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "# gspread stuff (https://www.twilio.com/blog/2017/02/an-easy-way-to-read-and-write-to-a-google-spreadsheet-in-python.html)\n",
    "# After that, search Google Sheets API and enable it as well.\n",
    "\n",
    "print('\\nGetting credentials from json...')\n",
    "\n",
    "scope = ['https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('control-panel.json', scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "print('\\nOpening spreadsheet...')\n",
    "\n",
    "cp = client.open(\"Lisbon October 2019 Data Analytics Full Time | Control Panel v1.0\")\n",
    "\n",
    "labs = cp.get_worksheet(9)\n",
    "\n",
    "lab_cp = dict(zip([labs.cell(2,i).value for i in range(4,63)], list(range(4,63))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lab-resolving-git-conflicts': 4,\n",
       " 'lab-tuple-set-dict': 5,\n",
       " 'lab-list-comprehensions': 6,\n",
       " 'lab-string-operations': 7,\n",
       " 'lab-numpy': 8,\n",
       " 'lab-functions': 9,\n",
       " 'lab-lambda-functions': 10,\n",
       " 'lab-intro-pandas': 11,\n",
       " 'lab-mysql-first-queries': 12,\n",
       " 'lab-mysql-select': 13,\n",
       " 'lab-mysql': 14,\n",
       " 'lab-advanced-mysql': 15,\n",
       " 'lab-import-export': 16,\n",
       " 'lab-data-cleaning': 17,\n",
       " 'lab-map-reduce-filter': 18,\n",
       " 'lab-api-scavenger': 19,\n",
       " 'lab-advanced-regex': 20,\n",
       " 'lab-rss-feeds': 21,\n",
       " 'lab-web-scraping': 22,\n",
       " 'lab-matplotlib-seaborn': 23,\n",
       " 'lab-pandas-deep-dive': 24,\n",
       " 'lab-subsetting-and-descriptive-stats': 25,\n",
       " 'lab-understanding-descriptive-stats': 26,\n",
       " 'Report-EDA': 27,\n",
       " 'lab-regression-analysis': 28,\n",
       " 'lab-advanced-pandas': 29,\n",
       " 'lab-intro-prob': 30,\n",
       " 'lab-pivot-table-and-correlation': 31,\n",
       " 'lab-probability-distributions': 32,\n",
       " 'lab-confidence-intervals': 33,\n",
       " 'lab-intro-to-scipy': 34,\n",
       " 'lab-hypothesis-testing-1': 35,\n",
       " 'lab-hypothesis-testing-2': 36,\n",
       " 'lab-goodfit-indeptests': 37,\n",
       " 'lab-two-sample-hyp-test': 38,\n",
       " 'lab-reading-stats-concepts': 39,\n",
       " 'lab-storytelling-viz': 40,\n",
       " 'lab-tableau': 41,\n",
       " 'M2-mini-project1': 42,\n",
       " 'M2-mini-project2': 43,\n",
       " '': 51,\n",
       " 'lab-intro-to-ml': 52,\n",
       " 'lab-supervised-learning-feature-extraction': 53,\n",
       " 'lab-supervised-learning': 54,\n",
       " 'lab-supervised-learning-sklearn': 55,\n",
       " 'lab-unsupervised-learning': 56,\n",
       " 'lab-unsupervised-learning-and-sklearn': 57,\n",
       " 'lab-problems-in-ml': 58,\n",
       " 'lab-inbalance': 59,\n",
       " 'lab-deep-learning': 60,\n",
       " 'lab-nlp': 61,\n",
       " 'Day 5': 62}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lab-resolving-git-conflicts',\n",
       " 'lab-tuple-set-dict',\n",
       " 'lab-list-comprehensions',\n",
       " 'lab-string-operations',\n",
       " 'lab-numpy',\n",
       " 'lab-functions',\n",
       " 'lab-lambda-functions',\n",
       " 'lab-intro-pandas',\n",
       " 'lab-mysql-first-queries',\n",
       " 'lab-mysql-select',\n",
       " 'lab-mysql',\n",
       " 'lab-advanced-mysql',\n",
       " 'lab-import-export',\n",
       " 'lab-data-cleaning',\n",
       " 'lab-map-reduce-filter',\n",
       " 'lab-api-scavenger',\n",
       " 'lab-advanced-regex',\n",
       " 'lab-rss-feeds',\n",
       " 'lab-web-scraping',\n",
       " 'lab-matplotlib-seaborn',\n",
       " 'lab-pandas-deep-dive',\n",
       " 'lab-subsetting-and-descriptive-stats',\n",
       " 'lab-understanding-descriptive-stats',\n",
       " 'Report-EDA',\n",
       " 'lab-regression-analysis',\n",
       " 'lab-advanced-pandas',\n",
       " 'lab-intro-prob',\n",
       " 'lab-pivot-table-and-correlation',\n",
       " 'lab-probability-distributions',\n",
       " 'lab-confidence-intervals',\n",
       " 'lab-intro-to-scipy',\n",
       " 'lab-hypothesis-testing-1',\n",
       " 'lab-hypothesis-testing-2',\n",
       " 'lab-goodfit-indeptests',\n",
       " 'lab-two-sample-hyp-test',\n",
       " 'lab-reading-stats-concepts',\n",
       " 'lab-storytelling-viz',\n",
       " 'lab-tableau',\n",
       " 'M2-mini-project1',\n",
       " 'M2-mini-project2',\n",
       " '',\n",
       " 'lab-intro-to-ml',\n",
       " 'lab-supervised-learning-feature-extraction',\n",
       " 'lab-supervised-learning',\n",
       " 'lab-supervised-learning-sklearn',\n",
       " 'lab-unsupervised-learning',\n",
       " 'lab-unsupervised-learning-and-sklearn',\n",
       " 'lab-problems-in-ml',\n",
       " 'lab-inbalance',\n",
       " 'lab-deep-learning',\n",
       " 'lab-nlp',\n",
       " 'Day 5']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lab_cp.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "links.txt has been filled\n"
     ]
    }
   ],
   "source": [
    "# Import libraries:\n",
    "import csv\n",
    "import os\n",
    "import urllib.request, json \n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "\n",
    "# Get links:\n",
    "\n",
    "with open('lab_names.txt', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    lab_names = [name.strip(\"\\'\") for name in list(reader)[0]]\n",
    "\n",
    "path1 = 'https://api.github.com/repos/ta-data-lis/'\n",
    "path2 = '/pulls?state=open'\n",
    "\n",
    "with open('links.txt', 'w', newline='') as myfile:\n",
    "#          wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "#          wr.writerow(path1 + lab_name + path2)\n",
    "    for lab_name in lab_names:\n",
    "        myfile.write(\",\\\"\" + path1 + lab_name + path2 + \"\\\"\")\n",
    "print('links.txt has been filled')\n",
    "\n",
    "with open('links.txt', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    page_list = list(reader)[0][1:]\n",
    "    \n",
    "\n",
    "# Do the job:    \n",
    "\n",
    "token = '5e71cf50d45536be4e0ea4d94a5c70419d69fc72'\n",
    "\n",
    "zeroes = [] # labs with 0 open pull requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = page_list[-3]\n",
    "\n",
    "lab_name = url[39:].strip('pulls?state=open').strip('/')\n",
    "request = Request(url)\n",
    "request.add_header('Authorization', 'token %s' % token)\n",
    "response = urlopen(request)\n",
    "# print(response.read())\n",
    "data = json.loads(response.read().decode())\n",
    "\n",
    "count = 0\n",
    "\n",
    "lab_links = []\n",
    "\n",
    "for i in range(13):\n",
    "\n",
    "    try:\n",
    "        lab_links.append('[' + data[i]['user']['login'] + ']' + '  ' + data[i]['html_url'])\n",
    "    except:\n",
    "        break\n",
    "\n",
    "count = i\n",
    "if not count:\n",
    "    zeroes.append(lab_name)\n",
    "\n",
    "else:\n",
    "    print('\\n' + str(count) + ' open PR for ' + lab_name + ':\\n')\n",
    "    lab_links.reverse()\n",
    "    print(*lab_links,sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in page_list:\n",
    "    \n",
    "    lab_name = url[39:].strip('pulls?state=open').strip('/')\n",
    "    request = Request(url)\n",
    "    request.add_header('Authorization', 'token %s' % token)\n",
    "    response = urlopen(request)\n",
    "    # print(response.read())\n",
    "    data = json.loads(response.read().decode())\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    lab_links = []\n",
    "    \n",
    "    for i in range(13):\n",
    "    \n",
    "        try:\n",
    "            lab_links.append('[' + data[i]['user']['login'] + ']' + '  ' + data[i]['html_url'])\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "    count = i\n",
    "    if not count:\n",
    "        zeroes.append(lab_name)\n",
    "        \n",
    "    else:\n",
    "        print('\\n' + str(count) + ' open PR for ' + lab_name + ':\\n')\n",
    "        lab_links.reverse()\n",
    "        print(*lab_links,sep='\\n')\n",
    "\n",
    "print('\\n\\n' + str(len(zeroes)) + ' labs with 0 PR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for flasky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "links.txt already existed \n",
      "1 open PR for lab-reading-stats-concepts:\n",
      " ['[Constanze05]  https://github.com/ta-data-lis/lab-reading-stats-concepts/pull/7'] \n",
      "5 open PR for lab-tableau:\n",
      " ['[frankcardozo]  https://github.com/ta-data-lis/lab-tableau/pull/7', '[lukessmalley]  https://github.com/ta-data-lis/lab-tableau/pull/6', '[Felipe-Hub]  https://github.com/ta-data-lis/lab-tableau/pull/5', '[Mariana427]  https://github.com/ta-data-lis/lab-tableau/pull/4', '[EvelienDonkers]  https://github.com/ta-data-lis/lab-tableau/pull/3'] \n",
      "5 open PR for M2-mini-project1:\n",
      " ['[EvelienDonkers]  https://github.com/ta-data-lis/M2-mini-project1/pull/5', '[luisbsaude]  https://github.com/ta-data-lis/M2-mini-project1/pull/4', '[dandoye]  https://github.com/ta-data-lis/M2-mini-project1/pull/3', '[mjvsilva]  https://github.com/ta-data-lis/M2-mini-project1/pull/2', '[Mariana427]  https://github.com/ta-data-lis/M2-mini-project1/pull/1'] \n",
      "\n",
      "36 labs with 0 PR\n"
     ]
    }
   ],
   "source": [
    "# %%writefile pull_checker.py\n",
    "# Import libraries:\n",
    "import csv\n",
    "import os\n",
    "import urllib.request, json \n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "result = []\n",
    "# Get links:\n",
    "\n",
    "with open('lab_names.txt', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    lab_names = [name.strip(\"\\'\") for name in list(reader)[0]]\n",
    "\n",
    "path1 = 'https://api.github.com/repos/ta-data-lis/'\n",
    "path2 = '/pulls?state=open'\n",
    "\n",
    "\n",
    "if not os.path.isfile('links.txt'):\n",
    "    \n",
    "    open('links.txt', 'a').close()\n",
    "    \n",
    "    for lab_name in lab_names:\n",
    "\n",
    "        with open('links.txt', 'a', newline='') as myfile:\n",
    "    #          wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    #          wr.writerow(path1 + lab_name + path2)\n",
    "            myfile.write(\",\\\"\" + path1 + lab_name + path2 + \"\\\"\")\n",
    "    result.append('links.txt has been filled')\n",
    "else:\n",
    "    result.append('links.txt already existed')\n",
    "\n",
    "with open('links.txt', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    page_list = list(reader)[0][1:]\n",
    "    \n",
    "\n",
    "# Do the job:    \n",
    "\n",
    "token = '5e71cf50d45536be4e0ea4d94a5c70419d69fc72'\n",
    "\n",
    "zeroes = [] # labs with 0 open pull requests\n",
    "\n",
    "for url in page_list:\n",
    "    \n",
    "    lab_name = url[39:].strip('pulls?state=open').strip('/')\n",
    "    request = Request(url)\n",
    "    request.add_header('Authorization', 'token %s' % token)\n",
    "    response = urlopen(request)\n",
    "    # print(response.read())\n",
    "    data = json.loads(response.read().decode())\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    lab_links = []\n",
    "    \n",
    "    for i in range(13):\n",
    "    \n",
    "        try:\n",
    "            lab_links.append('[' + data[i]['user']['login'] + ']' + '  ' + data[i]['html_url'])\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "    count = i\n",
    "    if not count:\n",
    "        zeroes.append(lab_name)\n",
    "        \n",
    "    else:\n",
    "        result.append('\\n' + str(count) + ' open PR for ' + lab_name + ':\\n')\n",
    "        result.append(lab_links)\n",
    "\n",
    "result.append('\\n\\n' + str(len(zeroes)) + ' labs with 0 PR')\n",
    "\n",
    "print(' '.join([str(elem) for elem in result]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all labs names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "lab-advanced-mysql\n",
      "lab-advanced-pandas\n",
      "lab-advanced-regex\n",
      "lab-api-scavenger\n",
      "lab-bag-of-words\n",
      "lab-bayesian-statistics\n",
      "lab-bi-analysis-tableau\n",
      "lab-coingecko-api\n",
      "lab-confidence-intervals\n",
      "lab-data-cleaning\n",
      "lab-functions\n",
      "lab-goodfit-indeptests\n",
      "lab-hypothesis-testing-1\n",
      "lab-hypothesis-testing-2\n",
      "lab-import-export\n",
      "lab-inbalance\n",
      "lab-intro-bi-tableau\n",
      "lab-intro-pandas\n",
      "lab-intro-prob\n",
      "lab-intro-to-scipy\n",
      "lab-lambda-functions\n",
      "lab-learning-evaluation\n",
      "lab-list-comprehensions\n",
      "lab-map-reduce-filter\n",
      "lab-matplotlib-seaborn\n",
      "lab-medium-article\n",
      "lab-mysql\n",
      "lab-mysql-first-queries\n",
      "lab-mysql-select\n",
      "lab-numpy\n",
      "lab-pandas-deep-dive\n",
      "lab-pivot-table-and-correlation\n",
      "lab-plot-series\n",
      "lab-probability-distributions\n",
      "lab-reading-stats-concepts\n",
      "lab-regression-analysis\n",
      "lab-resolving-git-conflicts\n",
      "lab-rss-feeds\n",
      "lab-storytelling-viz\n",
      "lab-string-operations\n",
      "lab-subsetting-and-descriptive-stats\n",
      "lab-supervised-learning\n",
      "lab-supervised-learning-feature-extraction\n",
      "lab-supervised-learning-sklearn\n",
      "lab-tableau\n",
      "lab-tableau-data-viz\n",
      "lab-tuple-set-dict\n",
      "lab-two-sample-hyp-test\n",
      "lab-understanding-descriptive-stats\n",
      "lab-understanding-others-code\n",
      "lab-unsupervised-learning\n",
      "lab-unsupervised-learning-and-sklearn\n",
      "lab-web-scraping\n",
      "M2-mini-project1\n",
      "M2-mini-project2\n",
      "machine-learning-day\n",
      "prework-labs\n",
      "Project-Week-2-Lisbon\n",
      "Project-Week-3-Data-Thieves\n",
      "Project-Week-4\n",
      "Project-Week-6-Tableau\n",
      "python-project\n",
      "supervised-learning-project\n",
      "unsupervised-learning-project\n"
     ]
    }
   ],
   "source": [
    "token = '5e71cf50d45536be4e0ea4d94a5c70419d69fc72'\n",
    "# lab_name = url[39:].strip('pulls?state=open').strip('/')\n",
    "url = 'https://api.github.com/users/ta-data-lis/repos?per_page=100'\n",
    "request = Request(url)\n",
    "request.add_header('Authorization', 'token %s' % token)\n",
    "response = urlopen(request)\n",
    "# print(response.read())\n",
    "data = json.loads(response.read().decode())\n",
    "print(len([data[i]['name'] for i,j in enumerate(data)][3:]))\n",
    "print(*[data[i]['name'] for i,j in enumerate(data)][3:], sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
